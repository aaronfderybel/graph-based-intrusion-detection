{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd90303-80d8-4e5a-b46e-12e1d482c210",
   "metadata": {},
   "source": [
    "# Train and evaluate graphs\n",
    "\n",
    "We can use the pytorch geometric library to make a graph model that can perform classification on different nodes in the graph. [link](https://pytorch-geometric.readthedocs.io/en/latest/)\n",
    "\n",
    "The graph created is the same as the one described in the paper of David P. et al [link](https://arxiv.org/pdf/2107.14756.pdf). We work with the pytorch geometric library to have acess to more recent algorithms that run on graphs.\n",
    "\n",
    "The graph contains two different node types. One node for each ip corresponding to a device and a node for each connection between ip's. Graphs with multiple node types are called heterogenous graphs. \n",
    "\n",
    "We use a transformer based graph neural network designed for heterogenous graphs and implemented in the pytorch geometric library, more details can be found in this paper\n",
    "[link](https://arxiv.org/abs/2003.01332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1b4e73-f02f-4304-9f0d-6a7e55b074b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/train/week1_prep_train.pkl','rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "\n",
    "with open('data/eval/week1_prep_val.pkl','rb') as f:\n",
    "    df_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a2060-ad2e-4e1a-9b65-2ecaed5fd23f",
   "metadata": {},
   "source": [
    "We define a class to convert the tabular data to graphs. For each node of type 'ip' corresponding to a device we add a feature based on the ip-adress. For each subnet in the network we create a column and convert ip adresses to a category, this can be seen in the function `encode_ip`.\n",
    "\n",
    "The nodes of type 'connection' contain a number of connection type features defined in the constructor of the class, see `self.conn_feat`. Each connection node also contains a label see `self.labels_cols_oh`.\n",
    "\n",
    "This way we can train an algorithm to classify the connection nodes that also use information from the structure of the graph and ip nodes. Such a graph is created in pieces for example of 200 rows of our tabular dataset, each row contains information about a connection between two devices. In this way we create a snapshot of the network. This is done in the function `process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccf68a0-b5c1-47ea-9d4d-5320a4df5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zelf grafen aanmaken per 200 connecties\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "class CICdata():\n",
    "    def __init__(self, path_data):\n",
    "        f = open(path_data,'rb')\n",
    "        self.df = pickle.load(f)\n",
    "        self.conn_feat = ['Duration', 'Packets', 'Bytes', 'Proto_ICMP ', 'Proto_IGMP ','Proto_TCP  ', 'Proto_UDP  ','flag_A', 'flag_P', 'flag_R', 'flag_S','flag_F', 'Tos_0', 'Tos_16', 'Tos_32', 'Tos_192']\n",
    "        self.label_cols_oh = ['attack_benign','attack_bruteForce', 'attack_dos', 'attack_pingScan', 'attack_portScan']\n",
    "        \n",
    "        \n",
    "    def make_ip_map(self, data):\n",
    "        unique_ip = np.unique(np.append(data['Src IP Addr'].to_numpy(), \n",
    "                                        data['Dst IP Addr'].to_numpy()))\n",
    "        return {ip:idx for idx, ip in enumerate(unique_ip)}\n",
    "    \n",
    "    def encode_ip(self, value):\n",
    "        temp = [0]*10\n",
    "        if value == '192.168.100.6': #internal web server\n",
    "            temp[0] = 1.0\n",
    "        elif value == '192.168.100.5': #internal file server\n",
    "            temp[1] = 1.0\n",
    "        elif value == '192.168.100.4': #internal mail server\n",
    "            temp[2] = 1.0\n",
    "        elif value == '192.168.100.3': #internal backup server\n",
    "            temp[3] = 1.0\n",
    "        elif value[:11] == '192.168.100': #server subnet\n",
    "            temp[4] = 1.0\n",
    "        elif value[:11] == '192.168.200': #management subnet\n",
    "            temp[5] = 1.0\n",
    "        elif value[:11] == '192.168.210': #office subnet\n",
    "            temp[6] = 1.0\n",
    "        elif value[:11] == '192.168.220': #developer subnet\n",
    "            temp[7] = 1.0\n",
    "        elif value[5:6]=='_': #public ip\n",
    "            temp[8] = 1.0\n",
    "        elif value in ['0.0.0.0', '255.255.255.255']: #local ip\n",
    "            temp[9] = 1.0\n",
    "\n",
    "        return temp\n",
    "    \n",
    "    def get_ip_feat(self, ip_map):\n",
    "        ip_data = []\n",
    "        for ip, idx in ip_map.items():\n",
    "            ip_data.append(self.encode_ip(ip))\n",
    "        \n",
    "        return torch.tensor(ip_data).float()\n",
    "                \n",
    "    def make_edges(self, data, ip_map):\n",
    "        src = []\n",
    "        dst = []\n",
    "        count = 0\n",
    "        for _, row in data.iterrows():\n",
    "            #source ip to connection\n",
    "            src.append(ip_map[row['Src IP Addr']])\n",
    "            dst.append(count)\n",
    "\n",
    "            #destination ip to connection\n",
    "            src.append(ip_map[row['Dst IP Addr']])\n",
    "            dst.append(count)\n",
    "            count +=1\n",
    "\n",
    "        return torch.tensor([src, dst]), torch.tensor([dst, src])\n",
    "\n",
    "    def get_info_conn(self, data, cols):\n",
    "        return torch.tensor(data[cols].values)\n",
    "                \n",
    "    def process(self, n_rows=200):\n",
    "        x_conn = self.get_info_conn(self.df, self.conn_feat)\n",
    "        y = self.get_info_conn(self.df, self.label_cols_oh)\n",
    "        data_list = []\n",
    "        for i in tqdm(range(1, (len(self.df)//n_rows)+1), desc='processing'):\n",
    "            start_idx = (i-1)*n_rows\n",
    "            end_idx = i*n_rows\n",
    "            sample = self.df[start_idx:end_idx]\n",
    "            ip_map = self.make_ip_map(sample)\n",
    "            ip_to_conn, conn_to_ip = self.make_edges(sample, ip_map)\n",
    "            data = HeteroData()\n",
    "            data['ip'].x = self.get_ip_feat(ip_map) #encode ip's from the map\n",
    "            data['connection'].x = x_conn[start_idx:end_idx].float()\n",
    "            data['connection'].y = y[start_idx:end_idx]\n",
    "            data['ip','connection'].edge_index = ip_to_conn\n",
    "            data['connection','ip'].edge_index = conn_to_ip\n",
    "            data_list.append(data)\n",
    "        \n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0512ab-14d7-420e-897c-4b79e9433c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cic_data = CICdata('data/train/week1_prep_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f3dc1b-7a17-4330-80f2-7e5525625942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 10559/10559 [01:06<00:00, 159.85it/s]\n"
     ]
    }
   ],
   "source": [
    "data = cic_data.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043d33e-2883-4751-ab4c-e67c01017e42",
   "metadata": {},
   "source": [
    "We can display the types of nodes in our dataset along with the edges.\n",
    "* two node types: 'ip' and 'connection'.\n",
    "* two edge types: from ip to connection node or from connection to ip node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3457bfcb-26f0-4a86-9df5-2d46eb610f05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ip', 'connection']\n",
      "(['ip', 'connection'], [('ip', 'to', 'connection'), ('connection', 'to', 'ip')])\n"
     ]
    }
   ],
   "source": [
    "print(data[0].node_types)\n",
    "print(data[0].metadata())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb5a3e-3219-4894-938d-2ac17c47134d",
   "metadata": {},
   "source": [
    "A heterogenous graph transformer model can be easily made by using built-in classes. Some hyperparameters can be chosen such as the number of heads, hidden channels and number of layers.\n",
    "\n",
    "The number of out channels is always the number of unique label values (5 in the example dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a532b0bd-ed72-4f29-88c3-4541b65d4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "\n",
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, data_graph, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data_graph.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        print(self.lin_dict)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data_graph.metadata(),\n",
    "                           num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):        \n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return self.lin(x_dict['connection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e76484-6ac3-4818-b04d-77720a3951d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (ip): Linear(-1, 64, bias=True)\n",
      "  (connection): Linear(-1, 64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = HGT(data_graph= data[0], hidden_channels=64, out_channels=5,\n",
    "            num_heads=4, num_layers=2)\n",
    "# Initialize lazy module, still on cpu\n",
    "with torch.no_grad():\n",
    "    out = model(data[0].x_dict, data[0].edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00daa5d-9c27-4996-80b1-04cb2d143be0",
   "metadata": {},
   "source": [
    "The algorithm is trained with boilerplate pytorch code. The number of epochs and batch size can be adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e173f9c-5a82-4112-bad5-93d08269dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader, DataListLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#hyperparams\n",
    "EPOCHS = 20\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "train_loader = DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_examples = total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            batch.to(device)\n",
    "            out = model(batch.x_dict, batch.edge_index_dict)\n",
    "            #print(batch['connection'].y, batch['connection'].y.size())\n",
    "            # print(out, out.size())\n",
    "            loss = F.cross_entropy(out, batch['connection'].y.float())\n",
    "            #loss = focal_loss(out, batch['connection'].y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_examples += 64\n",
    "            total_loss += float(loss) * 64\n",
    "            \n",
    "        tqdm.write('EPOCH '+str(epoch)+' loss: '+ str(total_loss/total_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0837c27-7270-4411-b490-41b752bcba84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 loss: 1.0481664816086942\n",
      "EPOCH 1 loss: 0.16742647788205156\n",
      "EPOCH 2 loss: 0.016370172334030608\n",
      "EPOCH 3 loss: 0.01377640049393063\n",
      "EPOCH 4 loss: 0.012513390156549797\n",
      "EPOCH 5 loss: 0.011639993952915326\n",
      "EPOCH 6 loss: 0.010873084813912018\n",
      "EPOCH 7 loss: 0.0097299537721979\n",
      "EPOCH 8 loss: 0.008813250395916948\n",
      "EPOCH 9 loss: 0.007899739290008834\n",
      "EPOCH 10 loss: 0.0070540991671584905\n",
      "EPOCH 11 loss: 0.006732296295415312\n",
      "EPOCH 12 loss: 0.00582879560929679\n",
      "EPOCH 13 loss: 0.004940631523398528\n",
      "EPOCH 14 loss: 0.005108925253438374\n",
      "EPOCH 15 loss: 0.0056151988995032185\n",
      "EPOCH 16 loss: 0.004877394851813954\n",
      "EPOCH 17 loss: 0.003961015903835439\n",
      "EPOCH 18 loss: 0.003629152100824506\n",
      "EPOCH 19 loss: 0.0037679633526116075\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630a65b-e485-4786-a51f-c624c7c11d58",
   "metadata": {},
   "source": [
    "The tabular data for evaluation is converted into graphs and predictions are made with the now trained algorithm. Notice labels are extracted from the `connection` nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7635f94-c714-4f2c-9c04-bc93d952babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 2639/2639 [00:16<00:00, 161.34it/s]\n"
     ]
    }
   ],
   "source": [
    "cic_val = CICdata('data/eval/week1_prep_val.pkl')\n",
    "data_val = cic_val.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5fe6330-e468-4347-a599-0d3e3dc9446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2639/2639 [00:07<00:00, 332.47it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "count=0\n",
    "preds = []\n",
    "labels = []\n",
    "for graph in tqdm(data_val):\n",
    "    graph.to(device)\n",
    "    preds.append(model(graph.x_dict, graph.edge_index_dict).argmax(dim=1))\n",
    "    labels.append(graph['connection'].y.argmax(dim=1))\n",
    "\n",
    "preds = torch.cat(preds)\n",
    "labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a638397-5bf7-404c-9ac8-2301cad3c4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9970, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precise calculation of accuracy\n",
    "correct = (preds == labels).sum()\n",
    "acc = correct / len(preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2505821-427a-46bb-a9ed-e98f6c8b8b0e",
   "metadata": {},
   "source": [
    "The label values were one-hot encoded. The numbers [0, 1, 2, 3, 4] correspond to the different classes. We can convert these back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e82abfa0-40b5-4b8b-9191-5c49dc6939ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    323295\n",
      "           1       1.00      0.52      0.68       702\n",
      "           2       1.00      1.00      1.00    155977\n",
      "           3       0.55      0.52      0.53      1505\n",
      "           4       0.98      0.99      0.99     46321\n",
      "\n",
      "    accuracy                           1.00    527800\n",
      "   macro avg       0.91      0.80      0.84    527800\n",
      "weighted avg       1.00      1.00      1.00    527800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(preds.cpu(), labels.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df06187-42e5-4cb5-854d-65ae5f44bd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>benign</th>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>323295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruteforce</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>702.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dos</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>155977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pingscan</th>\n",
       "      <td>0.553100</td>\n",
       "      <td>0.515615</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>1505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portscan</th>\n",
       "      <td>0.983494</td>\n",
       "      <td>0.989163</td>\n",
       "      <td>0.986320</td>\n",
       "      <td>46321.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.996995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.907199</td>\n",
       "      <td>0.804639</td>\n",
       "      <td>0.840520</td>\n",
       "      <td>527800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.996917</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.996852</td>\n",
       "      <td>527800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support\n",
       "benign         0.999422  0.999991  0.999706  323295.000000\n",
       "bruteforce     1.000000  0.518519  0.682927     702.000000\n",
       "dos            0.999981  0.999910  0.999946  155977.000000\n",
       "pingscan       0.553100  0.515615  0.533700    1505.000000\n",
       "portscan       0.983494  0.989163  0.986320   46321.000000\n",
       "accuracy       0.996995  0.996995  0.996995       0.996995\n",
       "macro avg      0.907199  0.804639  0.840520  527800.000000\n",
       "weighted avg   0.996917  0.996995  0.996852  527800.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "map_class = {'0':'benign', '1':'bruteforce', '2':'dos', '3':'pingscan', '4':'portscan'}\n",
    "cr_df = pd.DataFrame(classification_report(preds.cpu(), labels.cpu(), output_dict=True)).transpose()\n",
    "temp = cr_df.index[:5].map(map_class).append(cr_df.index[5:])\n",
    "cr_df.index = temp\n",
    "cr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196772a8-90d1-474e-babc-7029e22980e7",
   "metadata": {},
   "source": [
    "The results clearly show the `bruteforce` and `pingscan` attacks are much harder to detect. They also occur much less in the dataset according to the support column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370ccca-dd57-4a13-8083-555578eca0c6",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "We can visualize some of the attacks being detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f8e17-ad2e-46c9-8434-6b3320427dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (todo) use network x for this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAICIA",
   "language": "python",
   "name": "env_gaicia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
